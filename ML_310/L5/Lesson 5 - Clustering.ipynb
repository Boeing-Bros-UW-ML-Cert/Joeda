{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The main focus of this assignment is clustering from theoretical as well as practical perspective_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Clustering (Manually)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following dataset, perform the clustering “by hand”:\n",
    "\n",
    "17 28 50 60 80 89 150 167 171 189 \n",
    "1. \tUse the K-means algorithm with K= 3 to cluster the data \n",
    "<br><b> See L5_P1q1.jpg</b><br>\n",
    "2. \tUse hierarchical agglomerative clustering with single linkage to cluster the data\n",
    "<br><b> See L5_P1q2.jpg</b><br>\n",
    "3. \tUse hierarchical agglomerative clustering with complete linkage to cluster the data\n",
    "<br><b> See L5_P1q3.jpg</b><br>\n",
    "4. \tFor K-means What will the final clusters be after 3 iterations if k=3 and the initial centers are 150, 171 and 189\n",
    "<br><b> See L5_P1q4.jpg</b><br>\n",
    "\n",
    "Please see image files in the workspace as labeled. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: Do not write code to answer this question_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Clustering (Code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the dataset of accepted papers at the AAAI 2014 conference to find clusters of papers using K-Means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T01:17:23.647306Z",
     "start_time": "2019-06-12T01:17:22.620905Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the Relevant libraries\n",
    "import sklearn as sk\n",
    "import urllib\n",
    "\n",
    "# URL for the AAAI (UW Repository)\n",
    "#url = \"AAAI2014AcceptedPapers.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T01:17:27.945363Z",
     "start_time": "2019-06-12T01:17:23.650154Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T01:17:29.198058Z",
     "start_time": "2019-06-12T01:17:27.948355Z"
    }
   },
   "outputs": [],
   "source": [
    "# source for abstracts ... using actual URL to practice getting data from web\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00307/%5bUCI%5d%20AAAI-14%20Accepted%20Papers%20-%20Papers.csv\"\n",
    "\n",
    "# set up the data stream and put it into a df, and put the abstracts into a list\n",
    "papers_src = urllib.request.urlopen(url)\n",
    "papers = pd.read_csv(papers_src)\n",
    "papers.replace(to_replace=\"\\n\", value=\" \", regex=True, inplace=True)\n",
    "data = papers[\"abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T05:17:52.624101Z",
     "start_time": "2019-06-12T05:17:52.504468Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TfidfVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a3ae07fdce4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# initiatlize the vectorized; using this function since it takes care of normalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mvectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TfidfVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "# initiatlize the vectorized; using this function since it takes care of normalization\n",
    "vectorizer = TfidfVectorizer(min_df=0.05, max_df=0.2, max_features=250)\n",
    "V = vectorizer.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T01:36:58.654278Z",
     "start_time": "2019-06-12T01:36:47.577906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "running for 2 clusters\n",
      "cluster size\n",
      "0 / 196\n",
      "cluster words\n",
      "['models', 'information', 'classification', 'users', 'framework', 'task', 'image', 'domain', 'tasks', 'different']\n",
      "cluster size\n",
      "1 / 202\n",
      "cluster words\n",
      "['search', 'number', 'agents', 'planning', 'time', 'graph', 'game', 'constraints', 'set', 'when']\n",
      "=====================================\n",
      "running for 3 clusters\n",
      "cluster size\n",
      "0 / 47\n",
      "cluster words\n",
      "['agents', 'agent', 'game', 'strategy', 'preferences', 'form', 'design', 'when', 'optimal', 'where']\n",
      "cluster size\n",
      "1 / 141\n",
      "cluster words\n",
      "['classification', 'users', 'information', 'multi', 'domain', 'image', 'supervised', 'models', 'different', 'feature']\n",
      "cluster size\n",
      "2 / 210\n",
      "cluster words\n",
      "['time', 'search', 'planning', 'number', 'graph', 'constraints', 'set', 'first', 'models', 'over']\n",
      "=====================================\n",
      "running for 4 clusters\n",
      "cluster size\n",
      "0 / 103\n",
      "cluster words\n",
      "['models', 'users', 'social', 'probabilistic', 'user', 'prediction', 'information', 'networks', 'network', 'framework']\n",
      "cluster size\n",
      "1 / 73\n",
      "cluster words\n",
      "['graph', 'supervised', 'labels', 'multi', 'matrix', 'label', 'classification', 'datasets', 'image', 'low']\n",
      "cluster size\n",
      "2 / 30\n",
      "cluster words\n",
      "['domain', 'target', 'knowledge', 'tasks', 'task', 'source', 'language', 'classification', 'domains', 'single']\n",
      "cluster size\n",
      "3 / 192\n",
      "cluster words\n",
      "['search', 'planning', 'agents', 'time', 'number', 'game', 'constraints', 'when', 'agent', 'set']\n",
      "=====================================\n",
      "running for 5 clusters\n",
      "cluster size\n",
      "0 / 42\n",
      "cluster words\n",
      "['agents', 'agent', 'preferences', 'strategy', 'form', 'design', 'behavior', 'when', 'functions', 'where']\n",
      "cluster size\n",
      "1 / 149\n",
      "cluster words\n",
      "['planning', 'number', 'game', 'system', 'language', 'models', 'complexity', 'set', 'provide', 'natural']\n",
      "cluster size\n",
      "2 / 122\n",
      "cluster words\n",
      "['users', 'time', 'image', 'social', 'information', 'graph', 'user', 'models', 'large', 'matrix']\n",
      "cluster size\n",
      "3 / 56\n",
      "cluster words\n",
      "['domain', 'multi', 'classification', 'feature', 'label', 'labels', 'target', 'tasks', 'training', 'supervised']\n",
      "cluster size\n",
      "4 / 29\n",
      "cluster words\n",
      "['search', 'local', 'graph', 'instances', 'during', 'different', 'planning', 'outperforms', 'space', 'over']\n",
      "=====================================\n",
      "running for 6 clusters\n",
      "cluster size\n",
      "0 / 79\n",
      "cluster words\n",
      "['image', 'classification', 'feature', 'supervised', 'multi', 'domain', 'label', 'dimensional', 'approaches', 'features']\n",
      "cluster size\n",
      "1 / 80\n",
      "cluster words\n",
      "['agents', 'agent', 'behavior', 'optimal', 'preferences', 'when', 'strategy', 'single', 'design', 'any']\n",
      "cluster size\n",
      "2 / 113\n",
      "cluster words\n",
      "['time', 'graph', 'planning', 'complexity', 'number', 'first', 'probabilistic', 'models', 'order', 'constraints']\n",
      "cluster size\n",
      "3 / 28\n",
      "cluster words\n",
      "['users', 'social', 'user', 'different', 'information', 'networks', 'prediction', 'network', 'online', 'models']\n",
      "cluster size\n",
      "4 / 65\n",
      "cluster words\n",
      "['language', 'models', 'knowledge', 'tasks', 'game', 'task', 'natural', 'domain', 'system', 'information']\n",
      "cluster size\n",
      "5 / 33\n",
      "cluster words\n",
      "['search', 'best', 'local', 'instances', 'solutions', 'different', 'solution', 'set', 'all', 'constraints']\n"
     ]
    }
   ],
   "source": [
    "word_list = vectorizer.get_feature_names()\n",
    "results = {}\n",
    "for c in range(2,7):\n",
    "    # initialize Kmeans and fit the model\n",
    "    print(\"=====================================\")\n",
    "    print(\"running for {} clusters\".format(c))\n",
    "    km = KMeans(n_clusters=c, verbose=False)\n",
    "    km.fit(V)\n",
    "    vals, counts = np.unique(km.labels_, return_counts=True)\n",
    "    for v,c in zip(vals,counts):\n",
    "        print(\"cluster size\")\n",
    "        print(str(v) + \" / \" + str(c))\n",
    "        results[str(c)] = km.labels_\n",
    "        print(\"cluster words\")\n",
    "        print([word_list[w] for w in km.cluster_centers_.argsort()[:,::-1][v,:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1) Vary the number of K from 2 to 6 and show if the results vary and assess the clusters obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2) Make a case regarding which clusters ‘make sense’ e.g., is there a cluster were papers on reinforcement learning are together vs. another cluster which has papers on deep learning.\n",
    "As k goes up, there seem to be smaller clusters that form, with some bigger clusters next to them.  In those cases, there me be a bit of overfitting of the clusters, since they may be honing in on very particular words that may be more common in papers in general. \n",
    "\n",
    "It can be seen that some clusters appear to be related to some sort of game/task, others look at social networks or online users, others may look at probabilistic models, with other on classification and supervised learning.  \n",
    "\n",
    "It does appear to show some promise and may be able to use a bit more cleansing to get better results, since there are examples of words and their plural or alternative for that could be consilidated.  The number of appropriate clusters may be will be dependent on additional context of the business problem and what is attempting to be gleaned.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
